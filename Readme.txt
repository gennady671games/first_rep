Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.

Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Вам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком.

Постройте модель с предельно большим значением F1-меры. Чтобы сдать проект успешно, нужно довести метрику до 0.59. Проверьте F1-меру на тестовой выборке самостоятельно.

Дополнительно измеряйте AUC-ROC, сравнивайте её значение с F1-мерой.


Мы подготовили данные, избавились от лишних столбцов surname, row_number и customer_id. Столбец tenure привели к типу object и через метод get_dummies, вместе со столбцами geography и gender привели эти категориальные признаки к численным.
Провели небольшое исследование. Выяснили, что имеется зависимость от возраста (чем старше, тем выше вероятность ухода), количества продуктов (чем меньше продуктов банка использует клиент, тем выше вероятность ухода) и активности клиента (чем менее активен клиент, тем выше вероятность ухода). Также больше всего клиентов во Франции, но доля ушедших по отношению к общему количеству выше в Германии. Еще в общем количестве женщин меньше, но количество уходов больше.
Целевой признак был несбалансирован. Количество положительных исходов составляло лишь 1/5 от общего количества. Мы сбалансировали в дальнейшем.
Провели исследование моделей без учета дисбаланса и выяснили, что они неадекватны.
Провели масштабирование признаков и уравняли целевой признак, увеличив признак 1 в 4 раза.
Создали новые модели с учетом дисбаланса.
Модель градиентного бустинга отсеяли из-за низкого быстродействия и посредственных результатов.
Лучше всех была модель Random Forest с показателями F1: 0.9453430790571737 с параметрами: {'n_estimators': 48, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_depth': 69}. Логистическая регрессия не удовлетворила нашему показателю F1.
Проверили все получившиеся модели на тестовых выборках, предварительно дообучив их на общих данных по валидационной и обучающей выборке.
Второе место - модель решающего дерева с показателями F1: 0.7984251939579942 с параметрами: {'min_samples_split': 20, 'min_samples_leaf': 7, 'max_leaf_nodes': 56, 'max_depth': 83, 'criterion': 'gini'}
Самая лучшая модель - модель случайного леса с показателями Accuracy rf: 0.847, F1 rf: 0.598, ROC_auc rf: 0.741, Precision rf: 0.637, Recall rf: 0.564, что достигает всех наших целей по F1 выше 0,59.
Проверили получившиеся модели на адекватность в сравнении с дамми. Проверку прошли.